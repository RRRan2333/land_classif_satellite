{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras.applications import EfficientNetB0, ResNet50\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Geran\\AppData\\Local\\Temp\\ipykernel_17156\\2422719126.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if running the GPU version of tensorflow\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads directory of 3 datasets\n",
    "dir_train = pd.read_csv('dataset/EuroSAT/train.csv')\n",
    "dir_valid = pd.read_csv('dataset/EuroSAT/validation.csv')\n",
    "dir_test = pd.read_csv('dataset/EuroSAT/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24300, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnualCrop/AnnualCrop_142.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2835...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PermanentCrop/PermanentCrop_1073.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industrial/Industrial_453.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1810...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24295</th>\n",
       "      <td>SeaLake/SeaLake_1943.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24296</th>\n",
       "      <td>AnnualCrop/AnnualCrop_211.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24297</th>\n",
       "      <td>Industrial/Industrial_1428.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24298</th>\n",
       "      <td>AnnualCrop/AnnualCrop_2571.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24299</th>\n",
       "      <td>River/River_1418.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Label  \\\n",
       "0                          AnnualCrop/AnnualCrop_142.jpg      0   \n",
       "1      HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
       "2                   PermanentCrop/PermanentCrop_1073.jpg      6   \n",
       "3                          Industrial/Industrial_453.jpg      4   \n",
       "4      HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
       "...                                                  ...    ...   \n",
       "24295                           SeaLake/SeaLake_1943.jpg      9   \n",
       "24296                      AnnualCrop/AnnualCrop_211.jpg      0   \n",
       "24297                     Industrial/Industrial_1428.jpg      4   \n",
       "24298                     AnnualCrop/AnnualCrop_2571.jpg      0   \n",
       "24299                               River/River_1418.jpg      8   \n",
       "\n",
       "                  ClassName  \n",
       "0                AnnualCrop  \n",
       "1      HerbaceousVegetation  \n",
       "2             PermanentCrop  \n",
       "3                Industrial  \n",
       "4      HerbaceousVegetation  \n",
       "...                     ...  \n",
       "24295               SeaLake  \n",
       "24296            AnnualCrop  \n",
       "24297            Industrial  \n",
       "24298            AnnualCrop  \n",
       "24299                 River  \n",
       "\n",
       "[24300 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = pd.concat([dir_train, dir_valid], ignore_index=False)\n",
    "img_dir = img_dir.iloc[:,1:-1].reset_index().drop(['index'], axis=1)\n",
    "print(img_dir.shape)\n",
    "# img_dir = img_dir.iloc[:100, :] # limit sample size when testing\n",
    "img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels/classes\n",
    "images = []\n",
    "classes = []\n",
    "# labels.typeof()\n",
    "\n",
    "base_path = 'dataset/EuroSAT/'\n",
    "for index, row in img_dir.iterrows():\n",
    "    img_path = os.path.join(base_path, row['Filename'])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    classes.append(row['ClassName'])\n",
    "\n",
    "# Normalize images\n",
    "images = np.array(images) / 255.0\n",
    "labels = pd.get_dummies(classes).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24300, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the data augmentation\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "valid_data_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,115,850\n",
      "Trainable params: 527,626\n",
      "Non-trainable params: 23,588,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "\n",
    "def get_model(res=224, num_classes=10):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(res, res, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_1 = get_model()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "608/608 [==============================] - 202s 314ms/step - loss: 2.4490 - accuracy: 0.2387 - val_loss: 2.5210 - val_accuracy: 0.1852\n",
      "Epoch 2/10\n",
      "608/608 [==============================] - 165s 271ms/step - loss: 2.1902 - accuracy: 0.3122 - val_loss: 2.1244 - val_accuracy: 0.3280\n",
      "Epoch 3/10\n",
      "608/608 [==============================] - 167s 275ms/step - loss: 2.0353 - accuracy: 0.3557 - val_loss: 2.0757 - val_accuracy: 0.3427\n",
      "Epoch 4/10\n",
      "608/608 [==============================] - 210s 345ms/step - loss: 1.9206 - accuracy: 0.3870 - val_loss: 1.9762 - val_accuracy: 0.3193\n",
      "Epoch 5/10\n",
      "608/608 [==============================] - 151s 248ms/step - loss: 1.8336 - accuracy: 0.4049 - val_loss: 1.8358 - val_accuracy: 0.4317\n",
      "Epoch 6/10\n",
      "608/608 [==============================] - 183s 300ms/step - loss: 1.7611 - accuracy: 0.4210 - val_loss: 1.6896 - val_accuracy: 0.4344\n",
      "Epoch 7/10\n",
      "608/608 [==============================] - 197s 323ms/step - loss: 1.7091 - accuracy: 0.4313 - val_loss: 1.6745 - val_accuracy: 0.4688\n",
      "Epoch 8/10\n",
      "608/608 [==============================] - 205s 336ms/step - loss: 1.6685 - accuracy: 0.4417 - val_loss: 1.6202 - val_accuracy: 0.4332\n",
      "Epoch 9/10\n",
      "608/608 [==============================] - 238s 392ms/step - loss: 1.6334 - accuracy: 0.4478 - val_loss: 1.6487 - val_accuracy: 0.4141\n",
      "Epoch 10/10\n",
      "608/608 [==============================] - 202s 332ms/step - loss: 1.6093 - accuracy: 0.4575 - val_loss: 1.6011 - val_accuracy: 0.4698\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_1.compile(optimizer=optimizers.Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "validation_steps = len(X_test) // batch_size\n",
    "\n",
    "history = model_1.fit(train_data_generator.flow(X_train, y_train, batch_size=batch_size), validation_data=valid_data_generator.flow(X_test, y_test, batch_size=batch_size), validation_steps=validation_steps, epochs=epochs)\n",
    "\n",
    "# Approximatley 50 mins/epoch (batch 32, ConvNeXt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "608/608 [==============================] - 179s 293ms/step - loss: 1.5853 - accuracy: 0.4629 - val_loss: 1.5202 - val_accuracy: 0.5517\n",
      "Epoch 12/20\n",
      "608/608 [==============================] - 189s 310ms/step - loss: 1.5673 - accuracy: 0.4717 - val_loss: 1.5356 - val_accuracy: 0.4996\n",
      "Epoch 13/20\n",
      "608/608 [==============================] - 189s 311ms/step - loss: 1.5423 - accuracy: 0.4805 - val_loss: 1.5088 - val_accuracy: 0.4828\n",
      "Epoch 14/20\n",
      "608/608 [==============================] - 202s 332ms/step - loss: 1.5341 - accuracy: 0.4818 - val_loss: 1.5164 - val_accuracy: 0.5182\n",
      "Epoch 15/20\n",
      "608/608 [==============================] - 195s 320ms/step - loss: 1.5254 - accuracy: 0.4853 - val_loss: 1.5380 - val_accuracy: 0.4561\n",
      "Epoch 16/20\n",
      "608/608 [==============================] - 201s 330ms/step - loss: 1.5019 - accuracy: 0.4888 - val_loss: 1.4502 - val_accuracy: 0.5627\n",
      "Epoch 17/20\n",
      "608/608 [==============================] - 201s 331ms/step - loss: 1.4973 - accuracy: 0.4918 - val_loss: 1.4783 - val_accuracy: 0.4507\n",
      "Epoch 18/20\n",
      "608/608 [==============================] - 205s 337ms/step - loss: 1.4731 - accuracy: 0.5016 - val_loss: 1.4212 - val_accuracy: 0.4998\n",
      "Epoch 19/20\n",
      "608/608 [==============================] - 222s 364ms/step - loss: 1.4599 - accuracy: 0.5043 - val_loss: 1.4023 - val_accuracy: 0.5420\n",
      "Epoch 20/20\n",
      "608/608 [==============================] - 202s 333ms/step - loss: 1.4560 - accuracy: 0.5081 - val_loss: 1.4976 - val_accuracy: 0.4344\n"
     ]
    }
   ],
   "source": [
    "# Continue training the model for another 10 epochs\n",
    "additional_epochs = 10\n",
    "total_epochs = epochs + additional_epochs\n",
    "\n",
    "history2 = model_1.fit(train_data_generator.flow(X_train, y_train, batch_size=batch_size), validation_dSata=valid_data_generator.flow(X_test, y_test, batch_size=batch_size), validation_steps=validation_steps, epochs=total_epochs, initial_epoch=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_resnet50_nFull_epoch20_batch32_lr.00001\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_resnet50_nFull_epoch20_batch32_lr.00001\\assets\n"
     ]
    }
   ],
   "source": [
    "# model_1.save(\"model_resnet50_nFull_epoch20_batch32_lr.00001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## if want to load later on: \n",
    "# from tensorflow.keras.models import load_model\n",
    "# model_1 = load_model(\"model_1_nFull_epoch5_batch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 640ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 1s 773ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "batch_size = 32  # Choose a smaller batch size according to your GPU memory capacity\n",
    "y_pred_batches = []\n",
    "\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    batch_pred = model_1.predict(X_test[i:i + batch_size])\n",
    "    y_pred_batches.append(batch_pred)\n",
    "\n",
    "y_pred = np.concatenate(y_pred_batches, axis=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# y_pred = model_1.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.78      0.62       551\n",
      "           1       0.75      0.07      0.12       547\n",
      "           2       0.00      0.00      0.00       535\n",
      "           3       0.23      0.75      0.35       459\n",
      "           4       0.89      0.83      0.86       453\n",
      "           5       0.46      0.02      0.03       371\n",
      "           6       0.50      0.04      0.08       456\n",
      "           7       0.83      0.81      0.82       502\n",
      "           8       0.00      0.00      0.00       469\n",
      "           9       0.32      0.95      0.48       517\n",
      "\n",
      "    accuracy                           0.43      4860\n",
      "   macro avg       0.45      0.42      0.34      4860\n",
      "weighted avg       0.45      0.43      0.34      4860\n",
      "\n",
      "[[431   0   0  73   1   0   0   1   0  45]\n",
      " [  0  36   0   5   0   6   0   0   0 500]\n",
      " [168   1   0 239  16   0  10  23   0  78]\n",
      " [ 57   2   0 344  10   0   8  13   0  25]\n",
      " [  2   0   0  44 378   0   1  28   0   0]\n",
      " [ 15   3   0  89   0   6   0   0   0 258]\n",
      " [120   0   0 294   5   0  19  11   0   7]\n",
      " [  0   1   0  82  11   0   0 408   0   0]\n",
      " [ 24   5   0 321   4   0   0  10   0 105]\n",
      " [ 26   0   0   1   0   1   0   0   0 489]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Geran\\anaconda3\\envs\\tfgpu_landclass\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Geran\\anaconda3\\envs\\tfgpu_landclass\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Geran\\anaconda3\\envs\\tfgpu_landclass\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_classes))\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you want to save the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.save(\"model_1\")\n",
    "\n",
    "# ## if want to load later on: \n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"model_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft / Archive (Plz disregard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt # somehow this just doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing/debugging\n",
    "# print(classes[0])\n",
    "# images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use this when running for 1st time\n",
    "# MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "# model = hub.load(MODEL_PATH)\n",
    "# # saved_model_path = 'model/'\n",
    "# # tf.saved_model.save(model, saved_model_path)\n",
    "\n",
    "# # ## Use this for subsequent runs when model already loaded locally\n",
    "# # saved_model_path = 'model/'\n",
    "# # model = tf.saved_model.load(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
