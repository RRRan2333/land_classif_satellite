{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Geran\\AppData\\Local\\Temp\\ipykernel_30236\\2422719126.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if running the GPU version of tensorflow\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads directory of 3 datasets\n",
    "dir_train = pd.read_csv('dataset/EuroSAT/train.csv')\n",
    "dir_valid = pd.read_csv('dataset/EuroSAT/validation.csv')\n",
    "dir_test = pd.read_csv('dataset/EuroSAT/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24300, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnualCrop/AnnualCrop_142.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2835...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PermanentCrop/PermanentCrop_1073.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industrial/Industrial_453.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1810...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24295</th>\n",
       "      <td>SeaLake/SeaLake_1943.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24296</th>\n",
       "      <td>AnnualCrop/AnnualCrop_211.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24297</th>\n",
       "      <td>Industrial/Industrial_1428.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24298</th>\n",
       "      <td>AnnualCrop/AnnualCrop_2571.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24299</th>\n",
       "      <td>River/River_1418.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Label  \\\n",
       "0                          AnnualCrop/AnnualCrop_142.jpg      0   \n",
       "1      HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
       "2                   PermanentCrop/PermanentCrop_1073.jpg      6   \n",
       "3                          Industrial/Industrial_453.jpg      4   \n",
       "4      HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
       "...                                                  ...    ...   \n",
       "24295                           SeaLake/SeaLake_1943.jpg      9   \n",
       "24296                      AnnualCrop/AnnualCrop_211.jpg      0   \n",
       "24297                     Industrial/Industrial_1428.jpg      4   \n",
       "24298                     AnnualCrop/AnnualCrop_2571.jpg      0   \n",
       "24299                               River/River_1418.jpg      8   \n",
       "\n",
       "                  ClassName  \n",
       "0                AnnualCrop  \n",
       "1      HerbaceousVegetation  \n",
       "2             PermanentCrop  \n",
       "3                Industrial  \n",
       "4      HerbaceousVegetation  \n",
       "...                     ...  \n",
       "24295               SeaLake  \n",
       "24296            AnnualCrop  \n",
       "24297            Industrial  \n",
       "24298            AnnualCrop  \n",
       "24299                 River  \n",
       "\n",
       "[24300 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = pd.concat([dir_train, dir_valid], ignore_index=False)\n",
    "img_dir = img_dir.iloc[:,1:-1].reset_index().drop(['index'], axis=1)\n",
    "print(img_dir.shape)\n",
    "# img_dir = img_dir.iloc[:100, :] # limit sample size when testing\n",
    "img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random, balanced subset of images\n",
    "num_samples_per_class = 100\n",
    "class_names = img_dir['ClassName'].unique()\n",
    "subset_idx = []\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_indices = img_dir[img_dir['ClassName'] == class_name].index\n",
    "    random_indices = np.random.choice(class_indices, num_samples_per_class, replace=False)\n",
    "    subset_idx.extend(random_indices)\n",
    "\n",
    "subset_img_dir = img_dir.loc[subset_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels/classes\n",
    "images = []\n",
    "classes = []\n",
    "# labels.typeof()\n",
    "\n",
    "base_path = 'dataset/EuroSAT/'\n",
    "for index, row in subset_img_dir.iterrows():\n",
    "    img_path = os.path.join(base_path, row['Filename'])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    classes.append(row['ClassName'])\n",
    "\n",
    "# Normalize images\n",
    "images = np.array(images) / 255.0\n",
    "labels = pd.get_dummies(classes).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the data augmentation\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "valid_data_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Geran\\AppData\\Local\\Temp\\ipykernel_30236\\1386802414.py:31: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=8, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "\n",
    "# hub_layer = hub.KerasLayer(model_path, trainable=False)\n",
    "\n",
    "def create_model(optimizer=\"adam\", learning_rate=0.001, num_dense_layers=1, dropout_rate=0.5):\n",
    "    optimizers = {\n",
    "        \"adam\": Adam(learning_rate=learning_rate),\n",
    "        \"rmsprop\": RMSprop(learning_rate=learning_rate)\n",
    "    }\n",
    "    \n",
    "    hub_layer = hub.KerasLayer(MODEL_PATH, trainable=False)\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.InputLayer((224, 224, 3)))\n",
    "    model.add(hub_layer)\n",
    "    \n",
    "    for _ in range(num_dense_layers):\n",
    "        model.add(layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers[optimizer], metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=3, batch_size=8, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cross validation with params: {'dropout_rate': 0.5, 'num_dense_layers': 1, 'learning_rate': 0.001}\n",
      "17/17 [==============================] - 29s 1s/step - loss: 1.9936 - accuracy: 0.5441\n",
      "Current Accuracy: 0.7528089880943298 || 45.23429727554321 \n",
      "17/17 [==============================] - 28s 1s/step - loss: 2.2429 - accuracy: 0.4803\n",
      "Current Accuracy: 0.8089887499809265 || 43.72777962684631 \n",
      "17/17 [==============================] - 29s 1s/step - loss: 1.8922 - accuracy: 0.5693\n",
      "Current Accuracy: 0.7932330965995789 || 45.19144654273987 \n",
      "Average accuracy: 0.7850102782249451\n",
      "Running cross validation with params: {'dropout_rate': 0.5, 'num_dense_layers': 1, 'learning_rate': 0.0001}\n",
      "17/17 [==============================] - 29s 1s/step - loss: 3.6870 - accuracy: 0.1632\n",
      "Current Accuracy: 0.28838950395584106 || 45.092397928237915 \n",
      "17/17 [==============================] - 30s 1s/step - loss: 3.6598 - accuracy: 0.1557\n",
      "Current Accuracy: 0.2846441864967346 || 46.21269774436951 \n",
      "17/17 [==============================] - 29s 1s/step - loss: 3.7064 - accuracy: 0.1461\n",
      "Current Accuracy: 0.2631579041481018 || 46.43091821670532 \n",
      "Average accuracy: 0.27873053153355914\n",
      "Running cross validation with params: {'dropout_rate': 0.5, 'num_dense_layers': 2, 'learning_rate': 0.001}\n",
      "17/17 [==============================] - 32s 1s/step - loss: 2.9002 - accuracy: 0.3565\n",
      "Current Accuracy: 0.5767790079116821 || 51.98375344276428 \n",
      "17/17 [==============================] - 28s 1s/step - loss: 2.9486 - accuracy: 0.3640\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'activation/Gelu/truediv' defined at (most recent call last):\nNode: 'activation/Gelu/truediv'\nfailed to allocate memory\n\t [[{{node activation/Gelu/truediv}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_516465]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m\n\u001b[0;32m     32\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[0;32m     33\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0.5\u001b[39m, \u001b[39m0.2\u001b[39m],\n\u001b[0;32m     34\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnum_dense_layers\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m],\n\u001b[0;32m     35\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0.001\u001b[39m, \u001b[39m0.0001\u001b[39m],\n\u001b[0;32m     36\u001b[0m }\n\u001b[0;32m     38\u001b[0m \u001b[39m# param_grid = {\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m#     \"dropout_rate\": [0.5, 0.2],\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m# }\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m best_params, best_accuracy \u001b[39m=\u001b[39m custom_cross_val(param_grid, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, X_train\u001b[39m=\u001b[39;49mX_train, y_train\u001b[39m=\u001b[39;49my_train)\n\u001b[0;32m     43\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest params: \u001b[39m\u001b[39m{\u001b[39;00mbest_params\u001b[39m}\u001b[39;00m\u001b[39m with accuracy: \u001b[39m\u001b[39m{\u001b[39;00mbest_accuracy\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mcustom_cross_val\u001b[1;34m(param_grid, cv, X_train, y_train)\u001b[0m\n\u001b[0;32m     20\u001b[0m model \u001b[39m=\u001b[39m create_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m     21\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_fold, y_train_fold)\n\u001b[1;32m---> 22\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(X_val_fold, y_val_fold, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     23\u001b[0m fold_scores\u001b[39m.\u001b[39mappend(accuracy)\n\u001b[0;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCurrent Accuracy: \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m || \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart_time\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Geran\\anaconda3\\envs\\tfgpu_landclass\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'activation/Gelu/truediv' defined at (most recent call last):\nNode: 'activation/Gelu/truediv'\nfailed to allocate memory\n\t [[{{node activation/Gelu/truediv}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_test_function_516465]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import itertools, time\n",
    "\n",
    "def custom_cross_val(param_grid, cv, X_train, y_train):\n",
    "    all_param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    param_combinations_scores = []\n",
    "\n",
    "    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "    for param_set in all_param_combinations:\n",
    "        params = dict(zip(param_grid.keys(), param_set))\n",
    "        print(f\"Running cross validation with params: {params}\")\n",
    "        fold_scores = []\n",
    "\n",
    "        for train_index, val_index in kfold.split(X_train, y_train):\n",
    "            start_time = time.time()\n",
    "            X_train_fold, y_train_fold = X_train[train_index], y_train[train_index]\n",
    "            X_val_fold, y_val_fold = X_train[val_index], y_train[val_index]\n",
    "\n",
    "            model = create_model(**params)\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "            fold_scores.append(accuracy)\n",
    "            print(f\"Current Accuracy: {accuracy} || {time.time() - start_time} \")\n",
    "\n",
    "        avg_accuracy = np.mean(fold_scores)\n",
    "        print(f\"Average accuracy: {avg_accuracy}\")\n",
    "        param_combinations_scores.append((params, avg_accuracy))\n",
    "\n",
    "    return max(param_combinations_scores, key=lambda x: x[1])\n",
    "\n",
    "param_grid = {\n",
    "    \"dropout_rate\": [0.5, 0.2],\n",
    "    \"num_dense_layers\": [1, 2],\n",
    "    \"learning_rate\": [0.001, 0.0001],\n",
    "}\n",
    "\n",
    "# param_grid = {\n",
    "#     \"dropout_rate\": [0.5, 0.2],\n",
    "# }\n",
    "\n",
    "best_params, best_accuracy = custom_cross_val(param_grid, cv=3, X_train=X_train, y_train=y_train)\n",
    "print(f\"Best params: {best_params} with accuracy: {best_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu_landclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
