{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Geran\\AppData\\Local\\Temp\\ipykernel_772\\2422719126.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if running the GPU version of tensorflow\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads directory of 3 datasets\n",
    "dir_train = pd.read_csv('dataset/EuroSAT/train.csv')\n",
    "dir_valid = pd.read_csv('dataset/EuroSAT/validation.csv')\n",
    "dir_test = pd.read_csv('dataset/EuroSAT/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## verify all 3 directories are equally sliced across 10 categories\n",
    "\n",
    "# temp1 = dir_test['Label'].value_counts() / dir_test.shape[0]\n",
    "# temp2 = dir_train['Label'].value_counts() / dir_train.shape[0]\n",
    "# temp3 = dir_valid['Label'].value_counts() / dir_valid.shape[0]\n",
    "# df_temp = pd.concat([temp1, temp2, temp3], axis=1)\n",
    "# df_temp\n",
    "\n",
    "# ## evenly sliced by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24300, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnualCrop/AnnualCrop_142.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2835...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PermanentCrop/PermanentCrop_1073.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industrial/Industrial_453.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1810...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24295</th>\n",
       "      <td>SeaLake/SeaLake_1943.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24296</th>\n",
       "      <td>AnnualCrop/AnnualCrop_211.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24297</th>\n",
       "      <td>Industrial/Industrial_1428.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24298</th>\n",
       "      <td>AnnualCrop/AnnualCrop_2571.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24299</th>\n",
       "      <td>River/River_1418.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Filename  Label  \\\n",
       "0                          AnnualCrop/AnnualCrop_142.jpg      0   \n",
       "1      HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
       "2                   PermanentCrop/PermanentCrop_1073.jpg      6   \n",
       "3                          Industrial/Industrial_453.jpg      4   \n",
       "4      HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
       "...                                                  ...    ...   \n",
       "24295                           SeaLake/SeaLake_1943.jpg      9   \n",
       "24296                      AnnualCrop/AnnualCrop_211.jpg      0   \n",
       "24297                     Industrial/Industrial_1428.jpg      4   \n",
       "24298                     AnnualCrop/AnnualCrop_2571.jpg      0   \n",
       "24299                               River/River_1418.jpg      8   \n",
       "\n",
       "                  ClassName  \n",
       "0                AnnualCrop  \n",
       "1      HerbaceousVegetation  \n",
       "2             PermanentCrop  \n",
       "3                Industrial  \n",
       "4      HerbaceousVegetation  \n",
       "...                     ...  \n",
       "24295               SeaLake  \n",
       "24296            AnnualCrop  \n",
       "24297            Industrial  \n",
       "24298            AnnualCrop  \n",
       "24299                 River  \n",
       "\n",
       "[24300 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = pd.concat([dir_train, dir_valid], ignore_index=False)\n",
    "img_dir = img_dir.iloc[:,1:-1].reset_index().drop(['index'], axis=1)\n",
    "print(img_dir.shape)\n",
    "# img_dir = img_dir.iloc[:100, :] # limit sample size when testing\n",
    "img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels/classes\n",
    "images = []\n",
    "classes = []\n",
    "# labels.typeof()\n",
    "\n",
    "# takes time. 3 mins on Geran's machine\n",
    "base_path = 'dataset/EuroSAT/'\n",
    "for index, row in img_dir.iterrows():\n",
    "    img_path = os.path.join(base_path, row['Filename'])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    classes.append(row['ClassName'])\n",
    "\n",
    "# Normalize images\n",
    "images = np.array(images) / 255.0\n",
    "labels = pd.get_dummies(classes).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## use this if want to test code with only parts of the images. \n",
    "# images\n",
    "# classes_orig = classes.copy()\n",
    "# images_orig = images.copy()\n",
    "# images = images[:1000]\n",
    "# classes = classes[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the min and max value of the list of 3-d arrays called images and return them in a tuple.\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def min_max(images):\n",
    "#     min_value = np.min(images)\n",
    "#     max_value = np.max(images)\n",
    "#     return (min_value, max_value)\n",
    "\n",
    "# min_max(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24300, 224, 224, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the data augmentation\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "valid_data_generator = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "\n",
    "# Define the pre-trained model to extract features\n",
    "def get_feature_extractor(model_path=MODEL_PATH, res=224):\n",
    "    hub_layer = hub.KerasLayer(model_path, trainable=False)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((res, res, 3)),\n",
    "            hub_layer\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "feature_extractor = get_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature extractions done in batches\n",
    "\n",
    "def predict_in_batches(model, data, batch_size=32):\n",
    "    num_batches = int(np.ceil(len(data) / batch_size))\n",
    "    features = []\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = (batch_idx + 1) * batch_size\n",
    "        \n",
    "        batch_data = data[batch_start:batch_end]\n",
    "        batch_features = model.predict(batch_data)\n",
    "        features.extend(batch_features)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Set the desired batch_size\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 8s 91ms/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 1s 1s/step\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'activation/Gelu/truediv' defined at (most recent call last):\nNode: 'activation/Gelu/truediv'\nfailed to allocate memory\n\t [[{{node activation/Gelu/truediv}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_31831]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Extract features from the training images\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_features \u001b[39m=\u001b[39m predict_in_batches(feature_extractor, X_train, batch_size)\n",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m, in \u001b[0;36mpredict_in_batches\u001b[1;34m(model, data, batch_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m     batch_end \u001b[39m=\u001b[39m (batch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m     11\u001b[0m     batch_data \u001b[39m=\u001b[39m data[batch_start:batch_end]\n\u001b[1;32m---> 12\u001b[0m     batch_features \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(batch_data)\n\u001b[0;32m     13\u001b[0m     features\u001b[39m.\u001b[39mextend(batch_features)\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(features)\n",
      "File \u001b[1;32mc:\\Users\\Geran\\anaconda3\\envs\\tfgpu_landclass\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'activation/Gelu/truediv' defined at (most recent call last):\nNode: 'activation/Gelu/truediv'\nfailed to allocate memory\n\t [[{{node activation/Gelu/truediv}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_31831]"
     ]
    }
   ],
   "source": [
    "# Extract features from the training images\n",
    "X_train_features = predict_in_batches(feature_extractor, X_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Extract features from the testing images\n",
    "X_test_features = predict_in_batches(feature_extractor, X_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265,994\n",
      "Trainable params: 265,482\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the fine-tuning model\n",
    "def get_fine_tuning_model(input_shape, num_classes=10):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer(input_shape),\n",
    "            # layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "            # layers.BatchNormalization(),\n",
    "            # layers.Dropout(0.5),\n",
    "            layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate the fine-tuning model\n",
    "input_shape = X_train_features.shape[1:]\n",
    "fine_tuning_model = get_fine_tuning_model(input_shape)\n",
    "fine_tuning_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 15ms/step - loss: 1.6552 - accuracy: 0.6388 - val_loss: 0.9293 - val_accuracy: 0.8300\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "fine_tuning_model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the fine-tuning model\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "validation_steps = len(X_test_features) // batch_size\n",
    "\n",
    "history = fine_tuning_model.fit(X_train_features, y_train, validation_data=(X_test_features, y_test), batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hub_layer = hub.KerasLayer(model_path, trainable=False)\n",
    "\n",
    "# def get_model(model_path=MODEL_PATH, res=224, num_classes=10):\n",
    "#     hub_layer = hub.KerasLayer(model_path, trainable=False)\n",
    "#     model = keras.Sequential(\n",
    "#         [\n",
    "#             keras.layers.InputLayer((res, res, 3)),\n",
    "#             hub_layer,\n",
    "#             # layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "#             # layers.BatchNormalization(),\n",
    "#             # layers.Dropout(0.5),\n",
    "#             layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "#             layers.BatchNormalization(),\n",
    "#             layers.Dropout(0.5),\n",
    "#             keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "#         ]\n",
    "#     )\n",
    "#     return model\n",
    "\n",
    "# model_1 = get_model()\n",
    "# model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "608/608 [==============================] - 881s 1s/step - loss: 0.8132 - accuracy: 0.8666 - val_loss: 0.6546 - val_accuracy: 0.9077\n",
      "Epoch 2/5\n",
      "608/608 [==============================] - 860s 1s/step - loss: 0.5642 - accuracy: 0.9164 - val_loss: 0.5445 - val_accuracy: 0.9178\n",
      "Epoch 3/5\n",
      "608/608 [==============================] - 856s 1s/step - loss: 0.4757 - accuracy: 0.9241 - val_loss: 0.4681 - val_accuracy: 0.9191\n",
      "Epoch 4/5\n",
      "608/608 [==============================] - 856s 1s/step - loss: 0.4222 - accuracy: 0.9257 - val_loss: 0.4230 - val_accuracy: 0.9243\n",
      "Epoch 5/5\n",
      "608/608 [==============================] - 855s 1s/step - loss: 0.3895 - accuracy: 0.9281 - val_loss: 0.4646 - val_accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "# ## Compile the model. \n",
    "#\n",
    "# ## TAKES TIME!! Unless using sebset of data, less epochs, etc. \n",
    "#\n",
    "# model_1.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# batch_size = 32\n",
    "# epochs = 5\n",
    "# validation_steps = len(X_test) // batch_size\n",
    "\n",
    "# history = model_1.fit(train_data_generator.flow(X_train, y_train, batch_size=batch_size), validation_data=valid_data_generator.flow(X_test, y_test, batch_size=batch_size), validation_steps=validation_steps, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 432). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1_nFull_epoch5_batch32\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1_nFull_epoch5_batch32\\assets\n"
     ]
    }
   ],
   "source": [
    "# model_1.save(\"model_1_nFull_epoch5_batch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if want to load later on: \n",
    "from tensorflow.keras.models import load_model\n",
    "model_1 = load_model(\"model_1_nFull_epoch5_batch32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "batch_size = 32  # Choose a smaller batch size according to your GPU memory capacity\n",
    "y_pred_batches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(X_test_features), batch_size):\n",
    "    batch_pred = fine_tuning_model.predict(X_test_features[i:i + batch_size])\n",
    "    y_pred_batches.append(batch_pred)\n",
    "\n",
    "y_pred = np.concatenate(y_pred_batches, axis=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# y_pred = model_1.predict(X_test)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "# y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        25\n",
      "           1       0.89      0.97      0.93        32\n",
      "           2       0.95      0.79      0.86        24\n",
      "           3       0.60      0.95      0.74        22\n",
      "           4       1.00      0.86      0.92        14\n",
      "           5       0.64      1.00      0.78        18\n",
      "           6       0.92      0.75      0.83        16\n",
      "           7       0.94      0.89      0.92        19\n",
      "           8       0.88      0.33      0.48        21\n",
      "           9       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.87      0.82      0.82       200\n",
      "weighted avg       0.86      0.83      0.82       200\n",
      "\n",
      "[[22  0  0  1  0  1  1  0  0  0]\n",
      " [ 0 31  0  0  0  1  0  0  0  0]\n",
      " [ 0  2 19  0  0  3  0  0  0  0]\n",
      " [ 1  0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0  2 12  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0]\n",
      " [ 0  0  1  1  0  1 12  1  0  0]\n",
      " [ 0  0  0  2  0  0  0 17  0  0]\n",
      " [ 1  1  0  8  0  4  0  0  7  0]\n",
      " [ 0  1  0  0  0  0  0  0  1  7]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred_classes))\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you want to save the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 432). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "# model_1.save(\"model_1\")\n",
    "\n",
    "# ## if want to load later on: \n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"model_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft / Archive (Plz disregard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt # somehow this just doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnualCrop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing/debugging\n",
    "# print(classes[0])\n",
    "# images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use this when running for 1st time\n",
    "# MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "# model = hub.load(MODEL_PATH)\n",
    "# # saved_model_path = 'model/'\n",
    "# # tf.saved_model.save(model, saved_model_path)\n",
    "\n",
    "# # ## Use this for subsequent runs when model already loaded locally\n",
    "# # saved_model_path = 'model/'\n",
    "# # model = tf.saved_model.load(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
