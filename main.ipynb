{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras import layers, models, optimizers, regularizers\n",
    "from keras.applications import EfficientNetB0\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if running the GPU version of tensorflow\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>Pasture/Pasture_1481.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>Pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2134</td>\n",
       "      <td>Forest/Forest_2638.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3518</td>\n",
       "      <td>Highway/Highway_875.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Highway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3048</td>\n",
       "      <td>River/River_434.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3996</td>\n",
       "      <td>SeaLake/SeaLake_2930.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>3735</td>\n",
       "      <td>SeaLake/SeaLake_1943.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>SeaLake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>4451</td>\n",
       "      <td>AnnualCrop/AnnualCrop_211.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>892</td>\n",
       "      <td>Industrial/Industrial_1428.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>4738</td>\n",
       "      <td>AnnualCrop/AnnualCrop_2571.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>3087</td>\n",
       "      <td>River/River_1418.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                        Filename  Label   ClassName\n",
       "0       258        Pasture/Pasture_1481.jpg      5     Pasture\n",
       "1      2134          Forest/Forest_2638.jpg      1      Forest\n",
       "2      3518         Highway/Highway_875.jpg      3     Highway\n",
       "3      3048             River/River_434.jpg      8       River\n",
       "4      3996        SeaLake/SeaLake_2930.jpg      9     SeaLake\n",
       "...     ...                             ...    ...         ...\n",
       "5395   3735        SeaLake/SeaLake_1943.jpg      9     SeaLake\n",
       "5396   4451   AnnualCrop/AnnualCrop_211.jpg      0  AnnualCrop\n",
       "5397    892  Industrial/Industrial_1428.jpg      4  Industrial\n",
       "5398   4738  AnnualCrop/AnnualCrop_2571.jpg      0  AnnualCrop\n",
       "5399   3087            River/River_1418.jpg      8       River\n",
       "\n",
       "[5400 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loads directory of 3 datasets\n",
    "dir_train = pd.read_csv('dataset/EuroSAT/train.csv')\n",
    "dir_valid = pd.read_csv('dataset/EuroSAT/validation.csv')\n",
    "dir_test = pd.read_csv('dataset/EuroSAT/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## verify all 3 directories are equally sliced across 10 categories\n",
    "\n",
    "# temp1 = dir_test['Label'].value_counts() / dir_test.shape[0]\n",
    "# temp2 = dir_train['Label'].value_counts() / dir_train.shape[0]\n",
    "# temp3 = dir_valid['Label'].value_counts() / dir_valid.shape[0]\n",
    "# df_temp = pd.concat([temp1, temp2, temp3], axis=1)\n",
    "# df_temp\n",
    "\n",
    "# ## evenly sliced by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24300, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnualCrop/AnnualCrop_142.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2835...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PermanentCrop/PermanentCrop_1073.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Industrial/Industrial_453.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1810...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Residential/Residential_2931.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>Residential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2176...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Forest/Forest_166.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>AnnualCrop/AnnualCrop_2425.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Residential/Residential_1371.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>Residential</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Filename  Label  \\\n",
       "0                        AnnualCrop/AnnualCrop_142.jpg      0   \n",
       "1    HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
       "2                 PermanentCrop/PermanentCrop_1073.jpg      6   \n",
       "3                        Industrial/Industrial_453.jpg      4   \n",
       "4    HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
       "..                                                 ...    ...   \n",
       "995                   Residential/Residential_2931.jpg      7   \n",
       "996  HerbaceousVegetation/HerbaceousVegetation_2176...      2   \n",
       "997                              Forest/Forest_166.jpg      1   \n",
       "998                     AnnualCrop/AnnualCrop_2425.jpg      0   \n",
       "999                   Residential/Residential_1371.jpg      7   \n",
       "\n",
       "                ClassName  \n",
       "0              AnnualCrop  \n",
       "1    HerbaceousVegetation  \n",
       "2           PermanentCrop  \n",
       "3              Industrial  \n",
       "4    HerbaceousVegetation  \n",
       "..                    ...  \n",
       "995           Residential  \n",
       "996  HerbaceousVegetation  \n",
       "997                Forest  \n",
       "998            AnnualCrop  \n",
       "999           Residential  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = pd.concat([dir_train, dir_valid], ignore_index=False)\n",
    "img_dir = img_dir.iloc[:,1:-1].reset_index().drop(['index'], axis=1)\n",
    "print(img_dir.shape)\n",
    "img_dir = img_dir.iloc[:1000, :] # limit sample size when testing\n",
    "img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels/classes\n",
    "images = []\n",
    "classes = []\n",
    "# labels.typeof()\n",
    "\n",
    "base_path = 'dataset/EuroSAT/'\n",
    "for index, row in img_dir.iterrows():\n",
    "    img_path = os.path.join(base_path, row['Filename'])\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    images.append(img)\n",
    "    classes.append(row['ClassName'])\n",
    "\n",
    "# Normalize images\n",
    "images = np.array(images) / 255.0\n",
    "labels = pd.get_dummies(classes).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the data augmentation\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=180,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_7 (KerasLayer)  (None, 1024)              87566464  \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 87,832,458\n",
      "Trainable params: 265,482\n",
      "Non-trainable params: 87,566,976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "\n",
    "# hub_layer = hub.KerasLayer(model_path, trainable=False)\n",
    "\n",
    "def get_model(model_path=MODEL_PATH, res=224, num_classes=10):\n",
    "    hub_layer = hub.KerasLayer(model_path, trainable=False)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.InputLayer((res, res, 3)),\n",
    "            hub_layer,\n",
    "            # layers.Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "            # layers.BatchNormalization(),\n",
    "            # layers.Dropout(0.5),\n",
    "            layers.Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)),\n",
    "            layers.BatchNormalization(),\n",
    "            # layers.Dropout(0.5),\n",
    "            keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model_1 = get_model()\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 44s 1s/step - loss: 1.5558 - accuracy: 0.6413 - val_loss: 1.2620 - val_accuracy: 0.7550\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 38s 2s/step - loss: 0.7826 - accuracy: 0.8763 - val_loss: 1.1796 - val_accuracy: 0.7650\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 37s 1s/step - loss: 0.7094 - accuracy: 0.8975 - val_loss: 1.0219 - val_accuracy: 0.8300\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.6444 - accuracy: 0.9275 - val_loss: 0.9887 - val_accuracy: 0.8150\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.6222 - accuracy: 0.9300 - val_loss: 0.8468 - val_accuracy: 0.8550\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.6197 - accuracy: 0.9225 - val_loss: 0.8098 - val_accuracy: 0.8700\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.5684 - accuracy: 0.9400 - val_loss: 0.8066 - val_accuracy: 0.8550\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.5169 - accuracy: 0.9600 - val_loss: 0.7664 - val_accuracy: 0.8850\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 35s 1s/step - loss: 0.5119 - accuracy: 0.9575 - val_loss: 0.8418 - val_accuracy: 0.8300\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 36s 1s/step - loss: 0.5232 - accuracy: 0.9463 - val_loss: 0.7825 - val_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model_1.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "history = model_1.fit(data_generator.flow(X_train, y_train, batch_size=batch_size), validation_data=(X_test, y_test), epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 980ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.80      0.87        25\n",
      "           1       0.84      0.97      0.90        32\n",
      "           2       0.85      0.71      0.77        24\n",
      "           3       0.94      0.77      0.85        22\n",
      "           4       0.87      0.93      0.90        14\n",
      "           5       0.71      0.83      0.77        18\n",
      "           6       0.75      0.75      0.75        16\n",
      "           7       0.94      0.89      0.92        19\n",
      "           8       0.86      0.90      0.88        21\n",
      "           9       0.75      1.00      0.86         9\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.85      0.86      0.85       200\n",
      "weighted avg       0.86      0.85      0.85       200\n",
      "\n",
      "[[20  0  0  0  0  2  2  0  0  1]\n",
      " [ 0 31  1  0  0  0  0  0  0  0]\n",
      " [ 0  4 17  0  0  2  0  0  0  1]\n",
      " [ 1  0  0 17  2  0  1  0  1  0]\n",
      " [ 0  0  0  0 13  0  0  1  0  0]\n",
      " [ 0  0  0  1  0 15  1  0  1  0]\n",
      " [ 0  0  1  0  0  1 12  0  1  1]\n",
      " [ 0  1  1  0  0  0  0 17  0  0]\n",
      " [ 0  1  0  0  0  1  0  0 19  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model_1.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes))\n",
    "print(confusion_matrix(y_true, y_pred_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you want to save the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 432). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save(\"model_1\")\n",
    "\n",
    "# ## if want to load later on: \n",
    "# from tensorflow.keras.models import load_model\n",
    "# loaded_model = load_model(\"model_1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft / Archive (Plz disregard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt # somehow this just doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnualCrop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing/debugging\n",
    "print(classes[0])\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Use this when running for 1st time\n",
    "# MODEL_PATH = \"https://tfhub.dev/sayakpaul/convnext_base_21k_1k_224_fe/1\"\n",
    "# model = hub.load(MODEL_PATH)\n",
    "# # saved_model_path = 'model/'\n",
    "# # tf.saved_model.save(model, saved_model_path)\n",
    "\n",
    "# # ## Use this for subsequent runs when model already loaded locally\n",
    "# # saved_model_path = 'model/'\n",
    "# # model = tf.saved_model.load(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
